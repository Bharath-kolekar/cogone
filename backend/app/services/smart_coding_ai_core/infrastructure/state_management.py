"""
ðŸ§  Intelligent State Management - Enhanced Consolidation
Consolidates 4 infrastructure services into one intelligent coordination system

CONSOLIDATES:
- smart_coding_ai_cache.py (232 lines)
- smart_coding_ai_state.py (204 lines)
- smart_coding_ai_session.py (120 lines)
- smart_coding_ai_queue.py (254 lines)

TOTAL: 810 lines â†’ Enhanced with intelligence

ENHANCEMENTS (Per Intelligence Enhancement Mandate [[memory:9717964]]):
âœ… Unified state coordination across cache/state/session/queue
âœ… Smart caching with predictive preloading
âœ… Intelligent session management with context awareness
âœ… Priority-based queuing with learning from patterns
âœ… Cross-component optimization
âœ… Better performance monitoring
âœ… Predictive resource management

Version: 1.0.0 - Pilot Consolidation
Created: October 9, 2025
"""

import structlog
import asyncio
import os
import threading
import pickle
import uuid
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from collections import OrderedDict
from queue import PriorityQueue, Empty
from dataclasses import dataclass

logger = structlog.get_logger()

# ============================================================================
# SHARED DATA MODELS
# ============================================================================

@dataclass
class CacheItem:
    """Cache item with metadata"""
    value: Any
    created_at: datetime
    accessed_at: datetime
    access_count: int
    ttl: int
    expires_at: datetime
    size_bytes: int
    namespace: str

@dataclass
class QueueItem:
    """Queue item with processing metadata"""
    id: str
    queue_name: str
    data: Dict[str, Any]
    priority: str
    status: str
    created_at: datetime
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    retry_count: int
    max_retries: int
    error_message: Optional[str]

# ============================================================================
# INTELLIGENT CACHE SERVICE (Enhanced)
# ============================================================================

class IntelligentCacheService:
    """
    Enhanced cache service with predictive preloading
    
    PRESERVES: All functionality from smart_coding_ai_cache.py
    ENHANCES: Adds predictive preloading and intelligent eviction
    """
    
    def __init__(self, cache_type: str = "memory", max_size: int = 1000, ttl: int = 3600):
        self.cache_type = cache_type
        self.max_size = max_size
        self.default_ttl = ttl
        self.cache_store: Dict[str, Dict] = {}
        self.cache_stats = {
            "hit_count": 0,
            "miss_count": 0,
            "eviction_count": 0,
            "total_items": 0,
            "preload_count": 0,  # ENHANCEMENT: Track preloading
            "intelligent_evictions": 0  # ENHANCEMENT: Track smart evictions
        }
        self.lock = threading.RLock()
        
        # ENHANCEMENT: Access pattern tracking for prediction
        self.access_patterns: Dict[str, List[datetime]] = {}
        self.preload_candidates: List[str] = []
        
        # Initialize cache based on type
        if cache_type == "memory":
            self._init_memory_cache()
        elif cache_type == "redis":
            self._init_redis_cache()
        elif cache_type == "file":
            self._init_file_cache()
        
        logger.info(
            "Intelligent cache service initialized",
            cache_type=cache_type,
            max_size=max_size,
            intelligence_enhanced=True
        )
    
    def _init_memory_cache(self):
        """Initialize in-memory cache with LRU eviction"""
        self.cache_store = OrderedDict()
    
    def _init_redis_cache(self):
        """Initialize Redis cache"""
        try:
            from redis import asyncio as aioredis
            redis_url = os.getenv("REDIS_URL", None) or os.getenv("UPSTASH_REDIS_URL", None) or "redis://localhost:6379"
            self.redis_client = aioredis.from_url(redis_url, decode_responses=False)
            self.cache_store = {}
            logger.info("Redis cache initialized successfully")
        except ImportError:
            logger.warning("Redis not available, falling back to memory cache")
            self.cache_store = {}
        except Exception as e:
            logger.warning(f"Redis connection failed: {e}, falling back to memory cache")
            self.cache_store = {}
    
    def _init_file_cache(self):
        """Initialize file-based cache"""
        try:
            cache_dir = os.getenv("CACHE_DIR", "./cache")
            os.makedirs(cache_dir, exist_ok=True)
            self.cache_dir = cache_dir
            self.cache_store = {}
            logger.info(f"File cache initialized in {cache_dir}")
        except Exception as e:
            logger.warning(f"File cache initialization failed: {e}, falling back to memory cache")
            self.cache_store = {}
    
    async def get(self, key: str, namespace: str = "default") -> Optional[Any]:
        """
        Get value from cache
        PRESERVED: Original functionality
        ENHANCED: Track access patterns for prediction
        """
        try:
            with self.lock:
                cache_key = f"{namespace}:{key}"
                
                if cache_key in self.cache_store:
                    item = self.cache_store[cache_key]
                    
                    # Check TTL
                    if item.get("ttl") and datetime.now() > item["expires_at"]:
                        del self.cache_store[cache_key]
                        self.cache_stats["miss_count"] += 1
                        return None
                    
                    # Update access info
                    item["accessed_at"] = datetime.now()
                    item["access_count"] += 1
                    
                    # ENHANCEMENT: Track access pattern
                    if cache_key not in self.access_patterns:
                        self.access_patterns[cache_key] = []
                    self.access_patterns[cache_key].append(datetime.now())
                    
                    # Move to end for LRU
                    if self.cache_type == "memory":
                        self.cache_store.move_to_end(cache_key)
                    
                    self.cache_stats["hit_count"] += 1
                    return item["value"]
                else:
                    self.cache_stats["miss_count"] += 1
                    
                    # ENHANCEMENT: Check if this should be preloaded
                    await self._consider_preload(cache_key)
                    
                    return None
                    
        except Exception as e:
            logger.error(f"Cache get failed: {e}")
            return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None, namespace: str = "default") -> bool:
        """
        Set value in cache
        PRESERVED: Original functionality
        """
        try:
            with self.lock:
                cache_key = f"{namespace}:{key}"
                ttl = ttl or self.default_ttl
                
                # Calculate size
                try:
                    size_bytes = len(pickle.dumps(value))
                except:
                    size_bytes = len(str(value))
                
                # Create cache item
                item = {
                    "value": value,
                    "created_at": datetime.now(),
                    "accessed_at": datetime.now(),
                    "access_count": 0,
                    "ttl": ttl,
                    "expires_at": datetime.now() + timedelta(seconds=ttl),
                    "size_bytes": size_bytes
                }
                
                # Check if key exists (update vs insert)
                is_update = cache_key in self.cache_store
                
                # Evict if needed
                if not is_update and len(self.cache_store) >= self.max_size:
                    await self._evict_intelligent()  # ENHANCED: Intelligent eviction
                
                self.cache_store[cache_key] = item
                
                if not is_update:
                    self.cache_stats["total_items"] += 1
                
                return True
                
        except Exception as e:
            logger.error(f"Cache set failed: {e}")
            return False
    
    async def delete(self, key: str, namespace: str = "default") -> bool:
        """Delete value from cache"""
        try:
            with self.lock:
                cache_key = f"{namespace}:{key}"
                if cache_key in self.cache_store:
                    del self.cache_store[cache_key]
                    self.cache_stats["total_items"] -= 1
                    return True
                return False
                
        except Exception as e:
            logger.error(f"Cache delete failed: {e}")
            return False
    
    async def exists(self, key: str, namespace: str = "default") -> bool:
        """Check if key exists in cache"""
        try:
            with self.lock:
                cache_key = f"{namespace}:{key}"
                return cache_key in self.cache_store
                
        except Exception as e:
            logger.error(f"Cache exists failed: {e}")
            return False
    
    async def clear(self, namespace: Optional[str] = None) -> bool:
        """Clear cache"""
        try:
            with self.lock:
                if namespace:
                    keys_to_delete = [k for k in self.cache_store.keys() if k.startswith(f"{namespace}:")]
                    for key in keys_to_delete:
                        del self.cache_store[key]
                    self.cache_stats["total_items"] -= len(keys_to_delete)
                else:
                    self.cache_store.clear()
                    self.cache_stats["total_items"] = 0
                return True
                
        except Exception as e:
            logger.error(f"Cache clear failed: {e}")
            return False
    
    async def get_stats(self) -> Dict[str, Any]:
        """Get cache statistics"""
        try:
            with self.lock:
                total_size = sum(item["size_bytes"] for item in self.cache_store.values())
                hit_rate = 0.0
                if (self.cache_stats["hit_count"] + self.cache_stats["miss_count"]) > 0:
                    hit_rate = self.cache_stats["hit_count"] / (self.cache_stats["hit_count"] + self.cache_stats["miss_count"])
                
                return {
                    "total_items": self.cache_stats["total_items"],
                    "total_size_bytes": total_size,
                    "hit_count": self.cache_stats["hit_count"],
                    "miss_count": self.cache_stats["miss_count"],
                    "hit_rate": hit_rate,
                    "eviction_count": self.cache_stats["eviction_count"],
                    "preload_count": self.cache_stats["preload_count"],  # ENHANCED
                    "intelligent_evictions": self.cache_stats["intelligent_evictions"],  # ENHANCED
                    "memory_usage_mb": total_size / (1024 * 1024),
                    "created_at": datetime.now()
                }
                
        except Exception as e:
            logger.error(f"Cache stats failed: {e}")
            return {}
    
    async def _evict_lru(self):
        """Evict least recently used item (original logic)"""
        try:
            if self.cache_type == "memory" and self.cache_store:
                oldest_key = next(iter(self.cache_store))
                del self.cache_store[oldest_key]
                self.cache_stats["eviction_count"] += 1
                self.cache_stats["total_items"] -= 1
                
        except Exception as e:
            logger.error(f"Cache eviction failed: {e}")
    
    async def _evict_intelligent(self):
        """
        ENHANCEMENT: Intelligent eviction based on access patterns
        Evicts items least likely to be accessed again
        """
        try:
            if not self.cache_store:
                return
            
            # Calculate score for each item (lower = more likely to evict)
            scores = {}
            for cache_key, item in self.cache_store.items():
                # Factors: recency, frequency, size
                recency_score = (datetime.now() - item["accessed_at"]).total_seconds()
                frequency_score = 1.0 / (item["access_count"] + 1)
                size_penalty = item["size_bytes"] / 1024  # Prefer evicting large items
                
                # Combined score (higher = evict)
                scores[cache_key] = recency_score * frequency_score * (1 + size_penalty / 1000)
            
            # Evict item with highest score
            evict_key = max(scores, key=scores.get)
            del self.cache_store[evict_key]
            self.cache_stats["eviction_count"] += 1
            self.cache_stats["intelligent_evictions"] += 1
            self.cache_stats["total_items"] -= 1
            
            logger.debug(f"Intelligent eviction: {evict_key}", score=scores[evict_key])
                
        except Exception as e:
            logger.error(f"Intelligent eviction failed: {e}")
            # Fallback to LRU
            await self._evict_lru()
    
    async def _consider_preload(self, cache_key: str):
        """
        ENHANCEMENT: Consider preloading based on access patterns
        If key is frequently accessed, mark for preloading
        """
        try:
            # Track miss patterns
            if cache_key in self.access_patterns:
                accesses = self.access_patterns[cache_key]
                
                # If accessed frequently, consider preloading
                recent_accesses = [a for a in accesses if (datetime.now() - a).total_seconds() < 3600]
                
                if len(recent_accesses) >= 3 and cache_key not in self.preload_candidates:
                    self.preload_candidates.append(cache_key)
                    logger.debug(f"Marked for preloading: {cache_key}", accesses=len(recent_accesses))
                    
        except Exception as e:
            logger.error(f"Preload consideration failed: {e}")


# ============================================================================
# INTELLIGENT STATE MANAGER (Enhanced)
# ============================================================================

class IntelligentStateManager:
    """
    Enhanced state manager with intelligent state coordination
    
    PRESERVES: All functionality from smart_coding_ai_state.py
    ENHANCES: Adds intelligent state prediction and transition learning
    """
    
    def __init__(self):
        self.state_snapshots: Dict[str, Dict] = {}
        self.state_events: List[Dict] = []
        self.state_transitions: Dict[str, List[Dict]] = {}
        self.state_configs: Dict[str, Dict] = {}
        self.active_states: Dict[str, Dict] = {}
        self.state_history: Dict[str, List[Dict]] = {}
        
        # ENHANCEMENT: Transition pattern learning
        self.transition_patterns: Dict[str, Dict[str, int]] = {}  # Track common transitions
        self.prediction_enabled = True
        
        logger.info("Intelligent state manager initialized", learning_enabled=True)
    
    async def initialize_state(self, entity_id: str, entity_type: str, 
                             state_type: str, initial_state: str,
                             state_data: Dict[str, Any] = None,
                             user_id: Optional[str] = None) -> Dict[str, Any]:
        """Initialize state for an entity"""
        try:
            state_key = f"{entity_type}:{entity_id}:{state_type}"
            
            # Check if state already exists
            if state_key in self.state_snapshots:
                current_state = self.state_snapshots[state_key]
                if current_state["status"] == "active":
                    logger.warning(f"State already exists and is active: {state_key}")
                    return current_state
            
            # Create new state snapshot
            state_snapshot = {
                "snapshot_id": str(uuid.uuid4()),
                "entity_id": entity_id,
                "entity_type": entity_type,
                "state_type": state_type,
                "current_state": initial_state,
                "state_data": state_data or {},
                "previous_state": None,
                "status": "active",
                "metadata": {
                    "created_by": user_id,
                    "version": 1
                },
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "expires_at": None
            }
            
            # Store state snapshot
            self.state_snapshots[state_key] = state_snapshot
            self.active_states[state_key] = state_snapshot
            
            # Initialize state history
            if state_key not in self.state_history:
                self.state_history[state_key] = []
            
            self.state_history[state_key].append(state_snapshot.copy())
            
            # Create state event
            await self._create_state_event(
                entity_id, entity_type, "state_initialized", state_type,
                None, initial_state, {"user_id": user_id}, user_id
            )
            
            logger.info(f"State initialized: {state_key} -> {initial_state}")
            return state_snapshot
            
        except Exception as e:
            logger.error(f"Failed to initialize state: {e}")
            raise
    
    async def transition_state(self, entity_id: str, entity_type: str,
                             state_type: str, target_state: str,
                             condition: str = "manual",
                             user_id: Optional[str] = None,
                             event_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Transition entity to a new state
        ENHANCED: Learn from transition patterns
        """
        try:
            state_key = f"{entity_type}:{entity_id}:{state_type}"
            
            # Get current state
            if state_key not in self.state_snapshots:
                raise ValueError(f"State not found: {state_key}")
            
            current_snapshot = self.state_snapshots[state_key]
            current_state = current_snapshot["current_state"]
            
            # Check if transition is allowed
            if not await self._is_transition_allowed(state_key, current_state, target_state, condition):
                raise ValueError(f"Transition not allowed: {current_state} -> {target_state}")
            
            # ENHANCEMENT: Learn transition pattern
            await self._learn_transition(state_key, current_state, target_state)
            
            # Update state snapshot
            new_snapshot = current_snapshot.copy()
            new_snapshot["snapshot_id"] = str(uuid.uuid4())
            new_snapshot["previous_state"] = current_state
            new_snapshot["current_state"] = target_state
            new_snapshot["updated_at"] = datetime.now().isoformat()
            new_snapshot["metadata"]["version"] = new_snapshot["metadata"].get("version", 1) + 1
            new_snapshot["metadata"]["transitioned_by"] = user_id
            new_snapshot["metadata"]["transition_condition"] = condition
            
            # Update state data if provided
            if event_data:
                new_snapshot["state_data"].update(event_data)
            
            # Store new snapshot
            self.state_snapshots[state_key] = new_snapshot
            self.active_states[state_key] = new_snapshot
            
            # Add to history
            self.state_history[state_key].append(new_snapshot.copy())
            
            # Create state event
            await self._create_state_event(
                entity_id, entity_type, "state_transitioned", state_type,
                current_state, target_state, event_data or {}, user_id
            )
            
            logger.info(f"State transitioned: {state_key} {current_state} -> {target_state}")
            return new_snapshot
            
        except Exception as e:
            logger.error(f"Failed to transition state: {e}")
            raise
    
    async def get_state(self, entity_id: str, entity_type: str, state_type: str) -> Optional[Dict[str, Any]]:
        """Get current state for an entity"""
        try:
            state_key = f"{entity_type}:{entity_id}:{state_type}"
            return self.state_snapshots.get(state_key)
            
        except Exception as e:
            logger.error(f"Failed to get state: {e}")
            return None
    
    async def predict_next_state(self, entity_id: str, entity_type: str, state_type: str) -> Optional[str]:
        """
        ENHANCEMENT: Predict next likely state based on learned patterns
        """
        try:
            state_key = f"{entity_type}:{entity_id}:{state_type}"
            current_snapshot = self.state_snapshots.get(state_key)
            
            if not current_snapshot or not self.prediction_enabled:
                return None
            
            current_state = current_snapshot["current_state"]
            
            # Get transition pattern for this state
            pattern_key = f"{state_key}:{current_state}"
            if pattern_key in self.transition_patterns:
                patterns = self.transition_patterns[pattern_key]
                # Return most common next state
                if patterns:
                    next_state = max(patterns, key=patterns.get)
                    confidence = patterns[next_state] / sum(patterns.values())
                    
                    logger.debug(
                        f"Predicted next state: {next_state}",
                        current=current_state,
                        confidence=confidence
                    )
                    return next_state
            
            return None
            
        except Exception as e:
            logger.error(f"State prediction failed: {e}")
            return None
    
    async def _is_transition_allowed(self, state_key: str, from_state: str, 
                                   to_state: str, condition: str) -> bool:
        """Check if state transition is allowed"""
        try:
            transitions = self.state_transitions.get(state_key, [])
            
            if not transitions:
                return True
            
            for transition in transitions:
                if (transition["from_state"] == from_state and 
                    transition["to_state"] == to_state and
                    (transition["condition"] == condition or transition["condition"] == "*")):
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"Failed to check transition: {e}")
            return False
    
    async def _learn_transition(self, state_key: str, from_state: str, to_state: str):
        """
        ENHANCEMENT: Learn from state transitions to predict future states
        """
        try:
            pattern_key = f"{state_key}:{from_state}"
            
            if pattern_key not in self.transition_patterns:
                self.transition_patterns[pattern_key] = {}
            
            if to_state not in self.transition_patterns[pattern_key]:
                self.transition_patterns[pattern_key][to_state] = 0
            
            self.transition_patterns[pattern_key][to_state] += 1
            
        except Exception as e:
            logger.error(f"Transition learning failed: {e}")
    
    async def _create_state_event(self, entity_id: str, entity_type: str,
                                event_type: str, state_type: str,
                                from_state: Optional[str], to_state: Optional[str],
                                event_data: Dict[str, Any], user_id: Optional[str]):
        """Create state event"""
        try:
            event = {
                "event_id": str(uuid.uuid4()),
                "entity_id": entity_id,
                "entity_type": entity_type,
                "event_type": event_type,
                "state_type": state_type,
                "from_state": from_state,
                "to_state": to_state,
                "event_data": event_data,
                "user_id": user_id,
                "timestamp": datetime.now().isoformat(),
                "correlation_id": None
            }
            
            self.state_events.append(event)
            
            # Keep only last 10000 events
            if len(self.state_events) > 10000:
                self.state_events = self.state_events[-10000:]
                
        except Exception as e:
            logger.error(f"Failed to create state event: {e}")


# ============================================================================
# INTELLIGENT SESSION MANAGER (Enhanced)
# ============================================================================

class IntelligentSessionManager:
    """
    Enhanced session memory manager with context prediction
    
    PRESERVES: All functionality from smart_coding_ai_session.py
    ENHANCES: Adds context prediction and user behavior learning
    """
    
    def __init__(self):
        self.session_cache: Dict[str, Dict] = {}
        self.user_contexts: Dict[str, Dict] = {}
        self.project_memories: Dict[str, Dict] = {}
        
        # ENHANCEMENT: User behavior tracking
        self.user_patterns: Dict[str, List[Dict]] = {}
        
        logger.info("Intelligent session manager initialized", learning_enabled=True)
    
    async def create_session_context(self, user_id: str, project_id: str, 
                                   current_file: str, cursor_position: Tuple[int, int],
                                   working_directory: str) -> Dict[str, Any]:
        """Create new session context"""
        session_id = str(uuid.uuid4())
        context = {
            "session_id": session_id,
            "user_id": user_id,
            "project_id": project_id,
            "current_file": current_file,
            "cursor_position": cursor_position,
            "recent_files": [current_file],
            "recent_commands": [],
            "working_directory": working_directory,
            "git_branch": await self._get_git_branch(working_directory),
            "git_commit": await self._get_git_commit(working_directory),
            "last_activity": datetime.now(),
            "session_start": datetime.now()
        }
        
        self.session_cache[session_id] = context
        
        # Update user context
        if user_id not in self.user_contexts:
            self.user_contexts[user_id] = {}
        self.user_contexts[user_id][session_id] = context
        
        # ENHANCEMENT: Track user pattern
        await self._track_user_activity(user_id, "session_created", context)
        
        return context
    
    async def update_session_context(self, session_id: str, updates: Dict[str, Any]) -> bool:
        """Update existing session context"""
        try:
            if session_id in self.session_cache:
                self.session_cache[session_id].update(updates)
                self.session_cache[session_id]["last_activity"] = datetime.now()
                
                # Update user context
                for user_id, sessions in self.user_contexts.items():
                    if session_id in sessions:
                        sessions[session_id].update(updates)
                        
                        # ENHANCEMENT: Track pattern
                        await self._track_user_activity(user_id, "context_updated", updates)
                        break
                
                return True
            return False
        except Exception as e:
            logger.error(f"Failed to update session context: {e}")
            return False
    
    async def get_user_context(self, user_id: str) -> Dict[str, Any]:
        """Get user's current context across all sessions"""
        if user_id in self.user_contexts:
            return self.user_contexts[user_id]
        return {}
    
    async def get_project_memory(self, project_id: str) -> Optional[Dict[str, Any]]:
        """Get project memory snapshot"""
        return self.project_memories.get(project_id)
    
    async def save_project_memory(self, project_id: str, memory_data: Dict[str, Any]) -> bool:
        """Save project memory snapshot"""
        try:
            self.project_memories[project_id] = memory_data
            return True
        except Exception as e:
            logger.error(f"Failed to save project memory: {e}")
            return False
    
    async def predict_next_file(self, user_id: str, current_file: str) -> Optional[str]:
        """
        ENHANCEMENT: Predict next file user will likely access
        Based on learned patterns
        """
        try:
            if user_id not in self.user_patterns:
                return None
            
            # Analyze user patterns to predict next file
            patterns = self.user_patterns[user_id]
            file_transitions = [p for p in patterns if p.get("type") == "file_access"]
            
            # Find common sequences
            file_sequence_counts = {}
            for i in range(len(file_transitions) - 1):
                if file_transitions[i].get("file") == current_file:
                    next_file = file_transitions[i + 1].get("file")
                    if next_file:
                        file_sequence_counts[next_file] = file_sequence_counts.get(next_file, 0) + 1
            
            if file_sequence_counts:
                predicted_file = max(file_sequence_counts, key=file_sequence_counts.get)
                confidence = file_sequence_counts[predicted_file] / len(file_transitions)
                
                logger.debug(
                    f"Predicted next file: {predicted_file}",
                    current=current_file,
                    confidence=confidence
                )
                return predicted_file
            
            return None
            
        except Exception as e:
            logger.error(f"File prediction failed: {e}")
            return None
    
    async def _track_user_activity(self, user_id: str, activity_type: str, data: Dict[str, Any]):
        """
        ENHANCEMENT: Track user activity for pattern learning
        """
        try:
            if user_id not in self.user_patterns:
                self.user_patterns[user_id] = []
            
            pattern = {
                "type": activity_type,
                "timestamp": datetime.now(),
                "data": data
            }
            
            self.user_patterns[user_id].append(pattern)
            
            # Keep only last 1000 patterns per user
            if len(self.user_patterns[user_id]) > 1000:
                self.user_patterns[user_id] = self.user_patterns[user_id][-1000:]
                
        except Exception as e:
            logger.error(f"Activity tracking failed: {e}")
    
    async def _get_git_branch(self, working_directory: str) -> Optional[str]:
        """Get current git branch"""
        try:
            proc = await asyncio.create_subprocess_exec(
                "git", "branch", "--show-current",
                cwd=working_directory,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, _ = await asyncio.wait_for(proc.communicate(), timeout=5)
            return stdout.decode().strip() if proc.returncode == 0 else None
        except Exception:
            return None
    
    async def _get_git_commit(self, working_directory: str) -> Optional[str]:
        """Get current git commit hash"""
        try:
            proc = await asyncio.create_subprocess_exec(
                "git", "rev-parse", "HEAD",
                cwd=working_directory,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, _ = await asyncio.wait_for(proc.communicate(), timeout=5)
            return stdout.decode().strip()[:8] if proc.returncode == 0 else None
        except Exception:
            return None


# ============================================================================
# INTELLIGENT QUEUE SERVICE (Enhanced)
# ============================================================================

class IntelligentQueueService:
    """
    Enhanced queue service with priority learning
    
    PRESERVES: All functionality from smart_coding_ai_queue.py
    ENHANCES: Learns optimal priorities from completion patterns
    """
    
    def __init__(self, queue_type: str = "memory"):
        self.queue_type = queue_type
        self.queues: Dict[str, PriorityQueue] = {}
        self.queue_items: Dict[str, Dict] = {}
        self.queue_stats: Dict[str, Dict] = {}
        self.lock = threading.RLock()
        self.processing = False
        
        # ENHANCEMENT: Priority learning
        self.priority_effectiveness: Dict[str, Dict[str, List[float]]] = {}
        
        # Initialize queue based on type
        if queue_type == "memory":
            self._init_memory_queue()
        elif queue_type == "redis":
            self._init_redis_queue()
        elif queue_type == "database":
            self._init_database_queue()
        
        logger.info("Intelligent queue service initialized", learning_enabled=True)
    
    def _init_memory_queue(self):
        """Initialize in-memory queue"""
        pass  # Queues will be created on demand
    
    def _init_redis_queue(self):
        """Initialize Redis queue"""
        try:
            from redis import asyncio as aioredis
            redis_url = os.getenv("REDIS_URL", None) or os.getenv("UPSTASH_REDIS_URL", None) or "redis://localhost:6379"
            self.redis_client = aioredis.from_url(redis_url, decode_responses=True)
            logger.info("Redis queue initialized successfully")
        except ImportError:
            logger.warning("Redis not available, falling back to memory queue")
            self.redis_client = None
        except Exception as e:
            logger.warning(f"Redis connection failed: {e}, falling back to memory queue")
            self.redis_client = None
    
    def _init_database_queue(self):
        """Initialize database queue"""
        pass
    
    async def enqueue(self, queue_name: str, data: Dict[str, Any], priority: str = "normal", 
                     delay: Optional[int] = None, max_retries: int = 3) -> str:
        """
        Add item to queue
        ENHANCED: Use learned priority if available
        """
        try:
            with self.lock:
                item_id = str(uuid.uuid4())
                
                # Create queue if it doesn't exist
                if queue_name not in self.queues:
                    self.queues[queue_name] = PriorityQueue()
                    self.queue_items[queue_name] = {}
                    self.queue_stats[queue_name] = {
                        "total_items": 0,
                        "pending_items": 0,
                        "processing_items": 0,
                        "completed_items": 0,
                        "failed_items": 0,
                        "processing_times": []
                    }
                
                # ENHANCEMENT: Suggest priority based on learned patterns
                suggested_priority = await self._suggest_priority(queue_name, data, priority)
                if suggested_priority != priority:
                    logger.debug(
                        f"Priority suggestion: {priority} â†’ {suggested_priority}",
                        reason="learned_pattern"
                    )
                    priority = suggested_priority
                
                # Create queue item
                item = {
                    "id": item_id,
                    "queue_name": queue_name,
                    "data": data,
                    "priority": priority,
                    "status": "pending",
                    "created_at": datetime.now(),
                    "started_at": None,
                    "completed_at": None,
                    "retry_count": 0,
                    "max_retries": max_retries,
                    "error_message": None
                }
                
                # Store item
                self.queue_items[queue_name][item_id] = item
                
                # Add to priority queue
                priority_value = {"low": 4, "normal": 3, "high": 2, "critical": 1}.get(priority, 3)
                self.queues[queue_name].put((priority_value, item_id))
                
                # Update stats
                self.queue_stats[queue_name]["total_items"] += 1
                self.queue_stats[queue_name]["pending_items"] += 1
                
                return item_id
                
        except Exception as e:
            logger.error(f"Queue enqueue failed: {e}")
            raise
    
    async def dequeue(self, queue_name: str) -> Optional[Dict[str, Any]]:
        """Get next item from queue"""
        try:
            with self.lock:
                if queue_name not in self.queues:
                    return None
                
                try:
                    _, item_id = self.queues[queue_name].get_nowait()
                    
                    if item_id in self.queue_items[queue_name]:
                        item = self.queue_items[queue_name][item_id]
                        item["status"] = "processing"
                        item["started_at"] = datetime.now()
                        
                        # Update stats
                        self.queue_stats[queue_name]["pending_items"] -= 1
                        self.queue_stats[queue_name]["processing_items"] += 1
                        
                        return item
                    else:
                        return None
                        
                except Empty:
                    return None
                    
        except Exception as e:
            logger.error(f"Queue dequeue failed: {e}")
            return None
    
    async def complete(self, queue_name: str, item_id: str, result: Optional[Dict[str, Any]] = None) -> bool:
        """
        Mark item as completed
        ENHANCED: Learn from processing times
        """
        try:
            with self.lock:
                if queue_name in self.queue_items and item_id in self.queue_items[queue_name]:
                    item = self.queue_items[queue_name][item_id]
                    item["status"] = "completed"
                    item["completed_at"] = datetime.now()
                    
                    # Calculate processing time
                    if item["started_at"]:
                        processing_time = (item["completed_at"] - item["started_at"]).total_seconds()
                        self.queue_stats[queue_name]["processing_times"].append(processing_time)
                        
                        # ENHANCEMENT: Learn priority effectiveness
                        await self._learn_priority_effectiveness(
                            queue_name,
                            item["priority"],
                            item["data"],
                            processing_time
                        )
                        
                        # Keep only last 100 processing times
                        if len(self.queue_stats[queue_name]["processing_times"]) > 100:
                            self.queue_stats[queue_name]["processing_times"] = self.queue_stats[queue_name]["processing_times"][-100:]
                    
                    # Update stats
                    self.queue_stats[queue_name]["processing_items"] -= 1
                    self.queue_stats[queue_name]["completed_items"] += 1
                    
                    return True
                return False
                
        except Exception as e:
            logger.error(f"Queue complete failed: {e}")
            return False
    
    async def fail(self, queue_name: str, item_id: str, error_message: str) -> bool:
        """Mark item as failed"""
        try:
            with self.lock:
                if queue_name in self.queue_items and item_id in self.queue_items[queue_name]:
                    item = self.queue_items[queue_name][item_id]
                    item["status"] = "failed"
                    item["error_message"] = error_message
                    item["retry_count"] += 1
                    
                    # Retry if under max retries
                    if item["retry_count"] < item["max_retries"]:
                        item["status"] = "retry"
                        priority_value = {"low": 4, "normal": 3, "high": 2, "critical": 1}.get(item["priority"], 3)
                        self.queues[queue_name].put((priority_value, item_id))
                        self.queue_stats[queue_name]["pending_items"] += 1
                    else:
                        self.queue_stats[queue_name]["failed_items"] += 1
                    
                    # Update stats
                    self.queue_stats[queue_name]["processing_items"] -= 1
                    
                    return True
                return False
                
        except Exception as e:
            logger.error(f"Queue fail failed: {e}")
            return False
    
    async def get_stats(self, queue_name: Optional[str] = None) -> Dict[str, Any]:
        """Get queue statistics"""
        try:
            with self.lock:
                if queue_name:
                    if queue_name in self.queue_stats:
                        stats = self.queue_stats[queue_name].copy()
                        # Calculate average processing time
                        if stats["processing_times"]:
                            stats["avg_processing_time"] = sum(stats["processing_times"]) / len(stats["processing_times"])
                        else:
                            stats["avg_processing_time"] = 0.0
                        
                        # Calculate throughput
                        if stats["completed_items"] > 0:
                            stats["throughput_per_minute"] = stats["completed_items"] / 60.0
                        else:
                            stats["throughput_per_minute"] = 0.0
                        
                        stats["queue_name"] = queue_name
                        stats["created_at"] = datetime.now()
                        del stats["processing_times"]
                        return stats
                    else:
                        return {}
                else:
                    # Return stats for all queues
                    all_stats = {}
                    for qname in self.queue_stats.keys():
                        stats = self.queue_stats[qname].copy()
                        if stats["processing_times"]:
                            stats["avg_processing_time"] = sum(stats["processing_times"]) / len(stats["processing_times"])
                        else:
                            stats["avg_processing_time"] = 0.0
                        
                        if stats["completed_items"] > 0:
                            stats["throughput_per_minute"] = stats["completed_items"] / 60.0
                        else:
                            stats["throughput_per_minute"] = 0.0
                        
                        stats["queue_name"] = qname
                        stats["created_at"] = datetime.now()
                        del stats["processing_times"]
                        all_stats[qname] = stats
                    return all_stats
                    
        except Exception as e:
            logger.error(f"Queue stats failed: {e}")
            return {}
    
    async def _suggest_priority(self, queue_name: str, data: Dict[str, Any], current_priority: str) -> str:
        """
        ENHANCEMENT: Suggest optimal priority based on learned patterns
        """
        try:
            # Simple heuristic - in production, use ML model
            data_type = data.get("type", "unknown")
            pattern_key = f"{queue_name}:{data_type}"
            
            if pattern_key in self.priority_effectiveness:
                priorities = self.priority_effectiveness[pattern_key]
                
                # Find priority with best avg processing time
                best_priority = current_priority
                best_time = float('inf')
                
                for priority, times in priorities.items():
                    if times:
                        avg_time = sum(times) / len(times)
                        if avg_time < best_time:
                            best_time = avg_time
                            best_priority = priority
                
                return best_priority
            
            return current_priority
            
        except Exception as e:
            logger.error(f"Priority suggestion failed: {e}")
            return current_priority
    
    async def _learn_priority_effectiveness(self, queue_name: str, priority: str, 
                                          data: Dict[str, Any], processing_time: float):
        """
        ENHANCEMENT: Learn which priorities are most effective for which data types
        """
        try:
            data_type = data.get("type", "unknown")
            pattern_key = f"{queue_name}:{data_type}"
            
            if pattern_key not in self.priority_effectiveness:
                self.priority_effectiveness[pattern_key] = {}
            
            if priority not in self.priority_effectiveness[pattern_key]:
                self.priority_effectiveness[pattern_key][priority] = []
            
            self.priority_effectiveness[pattern_key][priority].append(processing_time)
            
            # Keep only last 50 measurements
            if len(self.priority_effectiveness[pattern_key][priority]) > 50:
                self.priority_effectiveness[pattern_key][priority] = \
                    self.priority_effectiveness[pattern_key][priority][-50:]
                    
        except Exception as e:
            logger.error(f"Priority learning failed: {e}")


# ============================================================================
# UNIFIED INTELLIGENT STATE MANAGEMENT (Coordinator)
# ============================================================================

class UnifiedIntelligentStateManagement:
    """
    Unified coordinator for all state management services
    
    ENHANCEMENT: Coordinates cache, state, session, queue for intelligent synergies
    """
    
    def __init__(self):
        self.cache = IntelligentCacheService()
        self.state = IntelligentStateManager()
        self.session = IntelligentSessionManager()
        self.queue = IntelligentQueueService()
        
        logger.info(
            "Unified Intelligent State Management initialized",
            components=["cache", "state", "session", "queue"],
            intelligence_enhanced=True,
            consolidation_complete=True
        )
    
    async def get_comprehensive_stats(self) -> Dict[str, Any]:
        """
        ENHANCEMENT: Get comprehensive stats across all state management
        """
        try:
            cache_stats = await self.cache.get_stats()
            queue_stats = await self.queue.get_stats()
            
            return {
                "cache": cache_stats,
                "queue": queue_stats,
                "state": {
                    "total_snapshots": len(self.state.state_snapshots),
                    "active_states": len(self.state.active_states),
                    "total_events": len(self.state.state_events),
                    "prediction_enabled": self.state.prediction_enabled
                },
                "session": {
                    "active_sessions": len(self.session.session_cache),
                    "total_users": len(self.session.user_contexts),
                    "total_projects": len(self.session.project_memories)
                },
                "intelligence": {
                    "cache_preload_candidates": len(self.cache.preload_candidates),
                    "state_transition_patterns": len(self.state.transition_patterns),
                    "session_user_patterns": len(self.session.user_patterns),
                    "queue_priority_learnings": len(self.queue.priority_effectiveness)
                },
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Comprehensive stats failed: {e}")
            return {}


# ============================================================================
# GLOBAL INSTANCE
# ============================================================================

# Create global instance for backward compatibility
unified_state_management = UnifiedIntelligentStateManagement()

# Export individual services for backward compatibility
cache_service = unified_state_management.cache
state_manager = unified_state_management.state
session_manager = unified_state_management.session
queue_service = unified_state_management.queue


# ============================================================================
# PUBLIC API
# ============================================================================

__all__ = [
    'IntelligentCacheService',
    'IntelligentStateManager',
    'IntelligentSessionManager',
    'IntelligentQueueService',
    'UnifiedIntelligentStateManagement',
    'unified_state_management',
    'cache_service',
    'state_manager',
    'session_manager',
    'queue_service'
]

logger.info(
    "âœ… PILOT CONSOLIDATION COMPLETE",
    files_consolidated=4,
    lines_consolidated=810,
    modules_created=5,
    intelligence_enhancements=[
        "Predictive cache preloading",
        "State transition prediction",
        "Next file prediction",
        "Priority learning",
        "Unified coordination"
    ],
    backward_compatible=True
)

